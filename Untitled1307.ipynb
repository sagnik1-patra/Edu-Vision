{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f1f2d0-d36c-4866-8bc1-b89ee9d0c3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_50d.csv\n",
      "[INFO] -> shape: (68175, 51)\n",
      "  Unnamed: 0         0         1         2         3         4         5  \\\n",
      "0      going  0.218232  0.997149 -0.788738  0.783706  1.412624  0.439875   \n",
      "1       just  0.328883 -0.323240  0.620974  0.063740  1.963643 -1.429922   \n",
      "2       like -1.443751  0.700020 -0.744764  1.168110  1.252286 -2.420375   \n",
      "\n",
      "          6         7         8  ...        40        41        42        43  \\\n",
      "0  3.179963 -0.552562  1.954441  ... -0.480890  0.680463  0.062857  0.563106   \n",
      "1  2.479352 -0.720906  0.302058  ... -1.106233 -0.080174  1.540606  0.702087   \n",
      "2  1.260556  1.910394  0.720410  ... -0.955688 -0.727729  1.993031 -0.579122   \n",
      "\n",
      "         44        45        46        47        48        49  \n",
      "0 -0.822027  0.301155 -0.354391  0.348030  1.651381 -1.720476  \n",
      "1  0.237602 -0.399902 -1.076104 -0.808779  0.899297 -0.640511  \n",
      "2  0.531914 -2.246910 -0.468811 -0.434437  1.417524  0.564740  \n",
      "\n",
      "[3 rows x 51 columns]\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_50d.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_50d.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_50d_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_50d_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_300d.csv\n",
      "[INFO] -> shape: (68175, 301)\n",
      "  Unnamed: 0         0         1         2         3         4         5  \\\n",
      "0      going  0.282224  0.216655 -0.836659 -0.063338 -0.208164  0.144238   \n",
      "1       just -0.112434  0.631439 -0.081427  0.288760  0.677108 -0.203446   \n",
      "2       like  0.631965 -0.453183 -0.256713  0.227004 -0.762930 -0.634983   \n",
      "\n",
      "          6         7         8  ...       290       291       292       293  \\\n",
      "0  1.155843 -0.331597  0.823568  ... -0.030745  0.585437  0.474711 -0.689789   \n",
      "1  0.820269 -0.031801 -0.704224  ...  0.021465 -0.480330  0.329963 -0.402903   \n",
      "2  0.233275  1.635337 -0.974890  ... -0.105838  0.893409  0.058053  0.674091   \n",
      "\n",
      "        294       295       296       297       298       299  \n",
      "0  0.030715  1.123113  0.119392 -0.719813 -0.882543  0.351690  \n",
      "1  0.168842  0.380508 -0.987448 -1.291400 -0.085132 -0.222390  \n",
      "2  0.925095  0.914846  0.048320 -0.386226  1.108918  0.008589  \n",
      "\n",
      "[3 rows x 301 columns]\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_300d.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_300d.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_300d_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_300d_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_200d.csv\n",
      "[INFO] -> shape: (68175, 201)\n",
      "  Unnamed: 0         0         1         2         3         4         5  \\\n",
      "0      going  0.044015  1.342416 -1.412476 -0.348398  0.534022 -0.090394   \n",
      "1       just  0.642159  0.150572 -0.173432 -0.412051  1.022869 -0.340515   \n",
      "2       like  1.238019 -0.524805  0.024699 -0.667531 -0.781462 -1.342516   \n",
      "\n",
      "          6         7         8  ...       190       191       192       193  \\\n",
      "0  0.890617 -1.134855  0.787304  ...  0.152795 -0.501554  0.386989  0.505511   \n",
      "1  1.413375 -1.566763  0.085107  ...  0.093432  0.922247 -0.671969  0.222342   \n",
      "2 -0.734957  0.557618  0.206994  ...  0.296384 -0.692021 -1.038457 -0.271869   \n",
      "\n",
      "        194       195       196       197       198       199  \n",
      "0  0.940245 -0.319933 -0.442732  1.099972  0.089878  0.496173  \n",
      "1 -0.026263 -0.331397 -0.134952  0.819051 -0.193490 -0.661362  \n",
      "2  0.024658 -0.494676  0.470446  0.482349 -0.348168  1.669300  \n",
      "\n",
      "[3 rows x 201 columns]\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_200d.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_200d.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_200d_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_200d_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_100d.csv\n",
      "[INFO] -> shape: (68175, 101)\n",
      "  Unnamed: 0         0         1         2         3         4         5  \\\n",
      "0      going  0.570654  0.256748 -1.236981 -0.738045  2.628270 -1.285098   \n",
      "1       just  1.107518  0.721995 -0.032140  0.036088  1.249167 -1.024640   \n",
      "2       like -0.727619  0.342989 -2.229607  0.316396  0.334122 -0.111786   \n",
      "\n",
      "          6         7         8  ...        90        91        92        93  \\\n",
      "0  2.156774 -0.559733  0.374292  ...  0.556200 -0.273825  1.291157  0.950802   \n",
      "1  0.892103 -0.047810  0.692347  ...  0.572637 -0.111408 -0.897691  1.003899   \n",
      "2  0.233063  2.804363 -1.014111  ...  1.061112  0.531627 -0.763836  0.107621   \n",
      "\n",
      "         94        95        96        97        98        99  \n",
      "0 -1.095594  0.573792 -0.960960 -0.861175  0.668691  0.206428  \n",
      "1 -1.661461  0.196081 -0.748643  0.398994 -0.224213 -0.521025  \n",
      "2 -2.126512 -0.506204 -1.563310 -0.011372 -0.357976  0.158978  \n",
      "\n",
      "[3 rows x 101 columns]\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_100d.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_100d.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_100d_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\MOOC_100d_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT50.csv\n",
      "[INFO] -> shape: (12032, 51)\n",
      "   Unnamed: 0   0   1   2         3   4   5   6         7   8  ...        40  \\\n",
      "0           0 NaN NaN NaN       NaN NaN NaN NaN  0.159590 NaN  ...  0.142421   \n",
      "1           1 NaN NaN NaN       NaN NaN NaN NaN  0.400817 NaN  ...  0.010408   \n",
      "2           2 NaN NaN NaN  0.016698 NaN NaN NaN  0.296180 NaN  ...  0.013897   \n",
      "\n",
      "   41        42        43  44        45  46  47  48  49  \n",
      "0 NaN  0.031115       NaN NaN       NaN NaN NaN NaN NaN  \n",
      "1 NaN  0.018375  0.022203 NaN  0.092137 NaN NaN NaN NaN  \n",
      "2 NaN  0.025747       NaN NaN  0.172405 NaN NaN NaN NaN  \n",
      "\n",
      "[3 rows x 51 columns]\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT50.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT50.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT50_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT50_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT100.csv\n",
      "[INFO] -> shape: (12032, 96)\n",
      "   Unnamed: 0   0         1         2   3   4   5   6         7   8  ...  90  \\\n",
      "0           0 NaN  0.099787       NaN NaN NaN NaN NaN  0.017042 NaN  ... NaN   \n",
      "1           1 NaN  0.133759       NaN NaN NaN NaN NaN       NaN NaN  ... NaN   \n",
      "2           2 NaN  0.091839  0.022707 NaN NaN NaN NaN       NaN NaN  ... NaN   \n",
      "\n",
      "   91  92  93  94  95  96  97        98        99  \n",
      "0 NaN NaN NaN NaN NaN NaN NaN       NaN  0.050494  \n",
      "1 NaN NaN NaN NaN NaN NaN NaN       NaN       NaN  \n",
      "2 NaN NaN NaN NaN NaN NaN NaN  0.021812       NaN  \n",
      "\n",
      "[3 rows x 96 columns]\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT100.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT100.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT100_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT100_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT200.csv\n",
      "[INFO] -> shape: (12032, 164)\n",
      "   Unnamed: 0   0   2   3   4   6         7  10  11  12  ...  188  189  190  \\\n",
      "0           0 NaN NaN NaN NaN NaN       NaN NaN NaN NaN  ...  NaN  NaN  NaN   \n",
      "1           1 NaN NaN NaN NaN NaN       NaN NaN NaN NaN  ...  NaN  NaN  NaN   \n",
      "2           2 NaN NaN NaN NaN NaN  0.011922 NaN NaN NaN  ...  NaN  NaN  NaN   \n",
      "\n",
      "   191  192  193  195  196  198       199  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN       NaN  \n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN  0.027666  \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN       NaN  \n",
      "\n",
      "[3 rows x 164 columns]\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT200.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT200.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT200_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT200_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT300.csv\n",
      "[INFO] -> shape: (12032, 239)\n",
      "   Unnamed: 0   2   3   4         6         7   8   9  10  11  ...  283  284  \\\n",
      "0           0 NaN NaN NaN  0.024154       NaN NaN NaN NaN NaN  ...  NaN  NaN   \n",
      "1           1 NaN NaN NaN  0.206583  0.011228 NaN NaN NaN NaN  ...  NaN  NaN   \n",
      "2           2 NaN NaN NaN  0.159991       NaN NaN NaN NaN NaN  ...  NaN  NaN   \n",
      "\n",
      "   289  292  293  294  295  296  297  298  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[3 rows x 239 columns]\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT300.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT300.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT300_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\DT300_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\Fine_grained_Categories.csv\n",
      "[INFO] -> shape: (12032, 1)\n",
      "  Fine-grained Categories\n",
      "0                 History\n",
      "1                 History\n",
      "2                 History\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\Fine_grained_Categories.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\Fine_grained_Categories.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\Fine_grained_Categories_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\Fine_grained_Categories_preview.yaml\n",
      "\n",
      "[INFO] Reading: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\General_Level_Categories.csv\n",
      "[INFO] -> shape: (12032, 1)\n",
      "  General-level Categories\n",
      "0       Art and Humanities\n",
      "1       Art and Humanities\n",
      "2       Art and Humanities\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\Edu Vision\\General_Level_Categories.pkl\n",
      "[WARN] Could not write HDF5: 'bool' object is not iterable\n",
      "       Hint: pip install tables (64-bit)\n",
      "[WRITE] JSONL   -> C:\\Users\\sagni\\Downloads\\Edu Vision\\General_Level_Categories.jsonl\n",
      "[WRITE] YAML(meta) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\General_Level_Categories_meta.yaml\n",
      "[WRITE] YAML(preview) -> C:\\Users\\sagni\\Downloads\\Edu Vision\\General_Level_Categories_preview.yaml\n",
      "\n",
      "[DONE] Artifacts written to: C:\\Users\\sagni\\Downloads\\Edu Vision\n",
      "Formats per file: .pkl, .h5, .jsonl, _meta.yaml, _preview.yaml\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# EduVision dataset packer: CSV -> PKL, HDF5, JSONL, YAML\n",
    "# ==========================================================\n",
    "import os, sys, json, math, gc\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# INPUT FILES (edit if needed)\n",
    "# ----------------------------\n",
    "inputs = [\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_50d.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_300d.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_200d.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_100d.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT50.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT100.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT200.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT300.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\Fine_grained_Categories.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\General_Level_Categories.csv\",\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# OUTPUT DIRECTORY\n",
    "# ----------------------------\n",
    "OUT_DIR = Path(r\"C:\\Users\\sagni\\Downloads\\Edu Vision\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "JSONL_CHUNK_ROWS = 50_000   # stream JSONL in chunks to avoid OOM\n",
    "YAML_PREVIEW_ROWS = 200     # small YAML preview (not entire dataset)\n",
    "HDF5_KEY = \"data\"           # HDF5 group key\n",
    "HDF5_COMP = dict(complevel=5, complib=\"blosc\")\n",
    "PRINT_HEAD = 3\n",
    "\n",
    "# ----------------------------\n",
    "# HELPERS\n",
    "# ----------------------------\n",
    "def basename_no_ext(p: Path) -> str:\n",
    "    \"\"\"safe base name without extension; handles .csv nicely.\"\"\"\n",
    "    return p.stem\n",
    "\n",
    "def compute_min_itemsize(df: pd.DataFrame) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    For object columns in df, compute a safe min_itemsize (HDF5 string storage).\n",
    "    Caps per-column size to avoid absurd values.\n",
    "    \"\"\"\n",
    "    obj_cols = [c for c in df.columns if df[c].dtype == object]\n",
    "    sizes = {}\n",
    "    for c in obj_cols:\n",
    "        # length over non-null values only\n",
    "        try:\n",
    "            lens = df[c].dropna().astype(str).str.len()\n",
    "            if lens.empty:\n",
    "                continue\n",
    "            L = int(lens.quantile(0.99))  # 99th percentile\n",
    "            L = max(8, min(L + 4, 50_000))  # pad a bit; cap at 50k\n",
    "            sizes[c] = L\n",
    "        except Exception:\n",
    "            # fallback conservative\n",
    "            sizes[c] = 1024\n",
    "    return sizes\n",
    "\n",
    "def to_jsonl_stream(df: pd.DataFrame, out_path: Path, chunk_rows: int = 50_000):\n",
    "    \"\"\"Stream DataFrame to JSON Lines file in chunks (records-per-line).\"\"\"\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        n = len(df)\n",
    "        if n == 0:\n",
    "            return\n",
    "        for start in range(0, n, chunk_rows):\n",
    "            end = min(start + chunk_rows, n)\n",
    "            chunk = df.iloc[start:end].where(pd.notna(df.iloc[start:end]), None)\n",
    "            records = chunk.to_dict(orient=\"records\")\n",
    "            for rec in records:\n",
    "                f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "            del chunk, records\n",
    "            gc.collect()\n",
    "\n",
    "def save_yaml(data, path: Path):\n",
    "    try:\n",
    "        import yaml\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not write YAML {path.name}: {e}\")\n",
    "\n",
    "def summarize_df(df: pd.DataFrame) -> Dict:\n",
    "    dtypes = df.dtypes.astype(str).to_dict()\n",
    "    cols = list(df.columns)\n",
    "    summary = {\n",
    "        \"rows\": int(df.shape[0]),\n",
    "        \"cols\": int(df.shape[1]),\n",
    "        \"columns\": cols,\n",
    "        \"dtypes\": dtypes,\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN LOOP\n",
    "# ----------------------------\n",
    "for raw in inputs:\n",
    "    in_path = Path(raw)\n",
    "    if not in_path.exists():\n",
    "        print(f\"[SKIP] Not found: {in_path}\")\n",
    "        continue\n",
    "\n",
    "    base = basename_no_ext(in_path)\n",
    "    print(f\"\\n[INFO] Reading: {in_path}\")\n",
    "    try:\n",
    "        # Try common CSV settings; some files may need sep handling (default ',')\n",
    "        df = pd.read_csv(in_path, low_memory=False)\n",
    "    except Exception as e_csv:\n",
    "        # If there's a delimiter/encoding issue, try python engine fallback\n",
    "        try:\n",
    "            df = pd.read_csv(in_path, low_memory=False, engine=\"python\")\n",
    "        except Exception as e2:\n",
    "            print(f\"[ERROR] Failed to read {in_path}: {e2}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"[INFO] -> shape: {df.shape}\")\n",
    "    try:\n",
    "        print(df.head(PRINT_HEAD))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Output paths\n",
    "    pkl_path   = OUT_DIR / f\"{base}.pkl\"\n",
    "    h5_path    = OUT_DIR / f\"{base}.h5\"\n",
    "    jsonl_path = OUT_DIR / f\"{base}.jsonl\"\n",
    "    yaml_meta  = OUT_DIR / f\"{base}_meta.yaml\"\n",
    "    yaml_prev  = OUT_DIR / f\"{base}_preview.yaml\"\n",
    "\n",
    "    # --------- PKL ----------\n",
    "    try:\n",
    "        df.to_pickle(pkl_path)\n",
    "        print(f\"[WRITE] Pickle  -> {pkl_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not write PKL: {e}\")\n",
    "\n",
    "    # --------- HDF5 ----------\n",
    "    try:\n",
    "        min_items = compute_min_itemsize(df)\n",
    "        # to_hdf will error if PyTables missing\n",
    "        df.to_hdf(\n",
    "            h5_path, key=HDF5_KEY, mode=\"w\",\n",
    "            format=\"table\", data_columns=False,\n",
    "            min_itemsize=min_items if min_items else None,\n",
    "            **HDF5_COMP\n",
    "        )\n",
    "        print(f\"[WRITE] HDF5    -> {h5_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not write HDF5: {e}\\n       Hint: pip install tables (64-bit)\")\n",
    "\n",
    "    # --------- JSONL (streaming) ----------\n",
    "    try:\n",
    "        to_jsonl_stream(df, jsonl_path, chunk_rows=JSONL_CHUNK_ROWS)\n",
    "        print(f\"[WRITE] JSONL   -> {jsonl_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not write JSONL: {e}\")\n",
    "\n",
    "    # --------- YAMLs ----------\n",
    "    # meta YAML (lightweight)\n",
    "    meta = summarize_df(df)\n",
    "    # include a tiny sample of rows/values per column length hints\n",
    "    try:\n",
    "        meta[\"non_null_counts\"] = df.notna().sum().astype(int).to_dict()\n",
    "        # sample column-wise max lengths for object columns\n",
    "        obj_cols = [c for c in df.columns if df[c].dtype == object]\n",
    "        obj_len = {}\n",
    "        for c in obj_cols:\n",
    "            try:\n",
    "                obj_len[c] = int(df[c].dropna().astype(str).str.len().quantile(0.99))\n",
    "            except Exception:\n",
    "                obj_len[c] = None\n",
    "        meta[\"object_length_p99\"] = obj_len\n",
    "    except Exception:\n",
    "        pass\n",
    "    save_yaml(meta, yaml_meta)\n",
    "    print(f\"[WRITE] YAML(meta) -> {yaml_meta}\")\n",
    "\n",
    "    # preview YAML (first N rows only)\n",
    "    try:\n",
    "        prev = df.head(YAML_PREVIEW_ROWS).where(pd.notna(df.head(YAML_PREVIEW_ROWS)), None)\n",
    "        # Convert preview to list of dicts to be YAML-friendly\n",
    "        preview_records = prev.to_dict(orient=\"records\")\n",
    "        save_yaml({\"preview_rows\": preview_records}, yaml_prev)\n",
    "        print(f\"[WRITE] YAML(preview) -> {yaml_prev}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not write preview YAML: {e}\")\n",
    "\n",
    "    # memory cleanup\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n[DONE] Artifacts written to:\", OUT_DIR)\n",
    "print(\"Formats per file: .pkl, .h5, .jsonl, _meta.yaml, _preview.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a8b92-7758-4f5a-82f8-92bafb3ee85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
