{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b450168-db26-46fc-bdf2-c7b02db3773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embeddings:   C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_300d.csv\n",
      "[INFO] Topic vectors: C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT300.csv\n",
      "[INFO] Embeddings: shape=(68175, 301)\n",
      "  Unnamed: 0         0         1         2         3         4         5         6  ...       292       293       294       295       296  \\\n",
      "0      going  0.282224  0.216655 -0.836659 -0.063338 -0.208164  0.144238  1.155843  ...  0.474711 -0.689789  0.030715  1.123113  0.119392   \n",
      "1       just -0.112434  0.631439 -0.081427  0.288760  0.677108 -0.203446  0.820269  ...  0.329963 -0.402903  0.168842  0.380508 -0.987448   \n",
      "2       like  0.631965 -0.453183 -0.256713  0.227004 -0.762930 -0.634983  0.233275  ...  0.058053  0.674091  0.925095  0.914846  0.048320   \n",
      "3       time -1.363892 -0.254021 -0.689795 -0.419093  0.412053 -0.395511  0.212262  ...  0.266910 -0.145627  0.734603 -0.001361 -0.661998   \n",
      "4      thing -0.381017  0.863210  0.528545  0.508915  0.237749  0.277165  1.016616  ...  0.114556  0.452468  0.706427  0.626805 -0.586004   \n",
      "\n",
      "        297       298       299  \n",
      "0 -0.719813 -0.882543  0.351690  \n",
      "1 -1.291400 -0.085132 -0.222390  \n",
      "2 -0.386226  1.108918  0.008589  \n",
      "3 -1.354438  0.563217 -0.117375  \n",
      "4 -0.991389  0.265829 -0.329494  \n",
      "\n",
      "[5 rows x 301 columns]\n",
      "[INFO] Topics: shape=(12032, 239)\n",
      "   Unnamed: 0   2   3   4         6         7   8   9  ...  289  292  293  294  295  296  297  298\n",
      "0           0 NaN NaN NaN  0.024154       NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "1           1 NaN NaN NaN  0.206583  0.011228 NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2           2 NaN NaN NaN  0.159991       NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "3           3 NaN NaN NaN  0.101968       NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4           4 NaN NaN NaN  0.078884       NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "\n",
      "[5 rows x 239 columns]\n",
      "[WARN] Row mismatch: embeddings=68175, topics=12032. Truncating to 12032.\n",
      "[INFO] Samples: 12032 | Features: 300 | Classes: 4\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Edu Vision\\eduvision_embeddings_corr_heatmap.png\n",
      "[WARN] Stratified split failed (The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.); using non-stratified split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:396: RuntimeWarning: invalid value encountered in divide\n",
      "  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] C:\\Users\\sagni\\Downloads\\Edu Vision\\eduvision_accuracy_over_epochs.png\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Edu Vision\\eduvision_accuracy_over_epochs.csv\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Edu Vision\\eduvision_confusion_matrix.png\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Edu Vision\\eduvision_classification_report.txt\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Edu Vision\\eduvision_predictions.csv (proba=True)\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Edu Vision\\eduvision_pipeline.pkl\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Edu Vision\\eduvision_model_meta.json\n",
      "\n",
      "[DONE] All artifacts saved in: C:\\Users\\sagni\\Downloads\\Edu Vision\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# EduVision â€” Prediction Pipeline + All Graphs & Heatmap\n",
    "# Trains on MOOC embeddings to predict Topic ArgMax labels.\n",
    "# Saves: model, predictions, heatmap, accuracy curve, confusion matrix, report\n",
    "# Output dir: C:\\Users\\sagni\\Downloads\\Edu Vision\n",
    "# ==========================================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss\n",
    "from joblib import dump\n",
    "\n",
    "# ----------------------------\n",
    "# Paths (edit if needed)\n",
    "# ----------------------------\n",
    "ROOT = Path(r\"C:\\Users\\sagni\\Downloads\\Edu Vision\")\n",
    "OUT  = ROOT\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prefer highest-dim embeddings / topics available\n",
    "EMB_CANDIDATES = [\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_300d.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_200d.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_100d.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Word Embeddings\\MOOC_50d.csv\",\n",
    "]\n",
    "TOPIC_CANDIDATES = [\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT300.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT200.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT100.csv\",\n",
    "    r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\archive\\Topic Vectors\\DT50.csv\",\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# Artifacts to save\n",
    "# ----------------------------\n",
    "HEATMAP_PNG   = OUT / \"eduvision_embeddings_corr_heatmap.png\"\n",
    "ACC_PNG       = OUT / \"eduvision_accuracy_over_epochs.png\"\n",
    "ACC_CSV       = OUT / \"eduvision_accuracy_over_epochs.csv\"\n",
    "CM_PNG        = OUT / \"eduvision_confusion_matrix.png\"\n",
    "REPORT_TXT    = OUT / \"eduvision_classification_report.txt\"\n",
    "PREDICTIONS_CSV = OUT / \"eduvision_predictions.csv\"\n",
    "MODEL_PKL     = OUT / \"eduvision_pipeline.pkl\"\n",
    "META_JSON     = OUT / \"eduvision_model_meta.json\"\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "TEST_SIZE    = 0.2\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS       = 12\n",
    "TOPK_SAVE    = 5           # save top-k predicted classes per row\n",
    "PRINT_HEAD   = 5\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def first_existing(paths):\n",
    "    for p in paths:\n",
    "        if Path(p).exists():\n",
    "            return Path(p)\n",
    "    return None\n",
    "\n",
    "def read_csv_smart(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path, low_memory=False)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, low_memory=False, engine=\"python\")\n",
    "\n",
    "def numeric_columns(df: pd.DataFrame):\n",
    "    return [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "def argmax_labels_from_topics(topics_df: pd.DataFrame) -> tuple[np.ndarray, list[str]]:\n",
    "    num_cols = numeric_columns(topics_df)\n",
    "    if not num_cols:\n",
    "        raise ValueError(\"No numeric columns found in topic vectors CSV.\")\n",
    "    X_topics = topics_df[num_cols].astype(float).to_numpy()\n",
    "    y = np.argmax(X_topics, axis=1).astype(int)\n",
    "    return y, num_cols\n",
    "\n",
    "def summarize(name, df):\n",
    "    print(f\"[INFO] {name}: shape={df.shape}\")\n",
    "    with pd.option_context(\"display.width\", 140, \"display.max_columns\", 16):\n",
    "        print(df.head(PRINT_HEAD))\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load data\n",
    "# ----------------------------\n",
    "emb_path   = first_existing(EMB_CANDIDATES)\n",
    "topic_path = first_existing(TOPIC_CANDIDATES)\n",
    "if emb_path is None:\n",
    "    raise SystemExit(\"[ERROR] No embeddings CSV found. Check paths.\")\n",
    "if topic_path is None:\n",
    "    raise SystemExit(\"[ERROR] No topic vectors CSV found. Check paths.\")\n",
    "\n",
    "print(f\"[INFO] Embeddings:   {emb_path}\")\n",
    "print(f\"[INFO] Topic vectors: {topic_path}\")\n",
    "\n",
    "emb_df   = read_csv_smart(emb_path)\n",
    "topic_df = read_csv_smart(topic_path)\n",
    "summarize(\"Embeddings\", emb_df)\n",
    "summarize(\"Topics\", topic_df)\n",
    "\n",
    "# Align by min length (defensive). If you have IDs, replace with a merge on that ID.\n",
    "n = min(len(emb_df), len(topic_df))\n",
    "if len(emb_df) != len(topic_df):\n",
    "    print(f\"[WARN] Row mismatch: embeddings={len(emb_df)}, topics={len(topic_df)}. Truncating to {n}.\")\n",
    "emb_df   = emb_df.iloc[:n].reset_index(drop=True)\n",
    "topic_df = topic_df.iloc[:n].reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Prepare features X and labels y\n",
    "# ----------------------------\n",
    "emb_cols = numeric_columns(emb_df)\n",
    "if len(emb_cols) < 5:\n",
    "    raise SystemExit(\"[ERROR] Not enough numeric columns in embeddings to train.\")\n",
    "\n",
    "X_all = emb_df[emb_cols].astype(float).to_numpy()\n",
    "y_all, topic_num_cols = argmax_labels_from_topics(topic_df)\n",
    "classes_all = np.unique(y_all)\n",
    "if len(classes_all) < 2:\n",
    "    raise SystemExit(\"[ERROR] Only one class found from topics. Need >=2 to train.\")\n",
    "\n",
    "print(f\"[INFO] Samples: {X_all.shape[0]} | Features: {X_all.shape[1]} | Classes: {len(classes_all)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Correlation Heatmap (embeddings)\n",
    "# ----------------------------\n",
    "corr = pd.DataFrame(X_all, columns=emb_cols).corr(numeric_only=True)\n",
    "plt.figure(figsize=(10, 8))\n",
    "im = plt.imshow(corr.values, aspect='auto')\n",
    "plt.xticks(range(corr.shape[1]), corr.columns, rotation=90, fontsize=7)\n",
    "plt.yticks(range(corr.shape[0]), corr.index, fontsize=7)\n",
    "plt.title(\"EduVision: Embeddings Feature Correlation Heatmap\")\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.savefig(HEATMAP_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] {HEATMAP_PNG}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Train/Test split (try stratified, else fallback)\n",
    "# ----------------------------\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_all, y_all, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_all\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"[WARN] Stratified split failed ({e}); using non-stratified split.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_all, y_all, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=None\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Model (SGDClassifier, multinomial logistic) + accuracy over epochs\n",
    "# ----------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        alpha=1e-4,\n",
    "        max_iter=1,                # manual epochs\n",
    "        learning_rate=\"optimal\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        warm_start=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "train_acc, test_acc, test_logloss = [], [], []\n",
    "for ep in range(EPOCHS):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_tr = pipe.predict(X_train)\n",
    "    y_te = pipe.predict(X_test)\n",
    "\n",
    "    train_acc.append(accuracy_score(y_train, y_tr))\n",
    "    test_acc.append(accuracy_score(y_test, y_te))\n",
    "\n",
    "    # log loss if proba available (SGDClassifier with log_loss gives predict_proba)\n",
    "    try:\n",
    "        proba = pipe.predict_proba(X_test)\n",
    "        # ensure columns correspond to pipe.classes_\n",
    "        test_logloss.append(log_loss(y_test, proba, labels=pipe.named_steps[\"clf\"].classes_))\n",
    "    except Exception:\n",
    "        test_logloss.append(np.nan)\n",
    "\n",
    "# Save accuracy curve PNG + CSV\n",
    "plt.figure(figsize=(8, 4.8))\n",
    "plt.plot(range(1, EPOCHS+1), train_acc, marker='o', label=\"Train Acc\")\n",
    "plt.plot(range(1, EPOCHS+1), test_acc,  marker='s', label=\"Test Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"EduVision: Accuracy over Epochs (Embeddings â†’ Topic ArgMax)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ACC_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] {ACC_PNG}\")\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"epoch\": list(range(1, EPOCHS+1)),\n",
    "    \"train_accuracy\": train_acc,\n",
    "    \"test_accuracy\": test_acc,\n",
    "    \"test_logloss\": test_logloss\n",
    "}).to_csv(ACC_CSV, index=False)\n",
    "print(f\"[SAVED] {ACC_CSV}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Final predictions on Test, Confusion Matrix, Report\n",
    "# ----------------------------\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Handle possibly missing classes in y_test/y_pred\n",
    "labels_present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels_present)\n",
    "\n",
    "plt.figure(figsize=(max(7.5, min(16, 0.5*len(labels_present)+4)), 6.5))\n",
    "im = plt.imshow(cm, aspect='auto')\n",
    "plt.title(\"EduVision: Confusion Matrix (Topic ArgMax)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.colorbar(im)\n",
    "plt.xticks(range(len(labels_present)), labels_present, rotation=45, ha='right')\n",
    "plt.yticks(range(len(labels_present)), labels_present)\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] {CM_PNG}\")\n",
    "\n",
    "report = classification_report(\n",
    "    y_test, y_pred,\n",
    "    labels=labels_present,\n",
    "    target_names=[f\"topic_{i}\" for i in labels_present],\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    ")\n",
    "with open(REPORT_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== EduVision: Embeddings -> Topic ArgMax ===\\n\\n\")\n",
    "    f.write(f\"Embeddings: {emb_path}\\nTopics: {topic_path}\\n\\n\")\n",
    "    f.write(report + \"\\n\")\n",
    "print(f\"[SAVED] {REPORT_TXT}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Save per-sample predictions CSV (with top-k probs)\n",
    "# ----------------------------\n",
    "pred_rows = []\n",
    "have_proba = False\n",
    "try:\n",
    "    proba = pipe.predict_proba(X_test)\n",
    "    have_proba = True\n",
    "    cls = pipe.named_steps[\"clf\"].classes_\n",
    "    for i, (yt, yp) in enumerate(zip(y_test, y_pred)):\n",
    "        row = {\n",
    "            \"row_index\": int(i),\n",
    "            \"true_label\": int(yt),\n",
    "            \"pred_label\": int(yp),\n",
    "            \"correct\": bool(yt == yp),\n",
    "        }\n",
    "        # top-k\n",
    "        topk = min(TOPK_SAVE, proba.shape[1])\n",
    "        idxs = np.argsort(proba[i])[::-1][:topk]\n",
    "        for rank, j in enumerate(idxs, 1):\n",
    "            row[f\"top{rank}_class\"] = int(cls[j])\n",
    "            row[f\"top{rank}_proba\"] = float(proba[i, j])\n",
    "        pred_rows.append(row)\n",
    "except Exception:\n",
    "    # Fallback: no probabilities available\n",
    "    for i, (yt, yp) in enumerate(zip(y_test, y_pred)):\n",
    "        pred_rows.append({\n",
    "            \"row_index\": int(i),\n",
    "            \"true_label\": int(yt),\n",
    "            \"pred_label\": int(yp),\n",
    "            \"correct\": bool(yt == yp),\n",
    "        })\n",
    "\n",
    "pd.DataFrame(pred_rows).to_csv(PREDICTIONS_CSV, index=False)\n",
    "print(f\"[SAVED] {PREDICTIONS_CSV} (proba={have_proba})\")\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Save model + metadata\n",
    "# ----------------------------\n",
    "dump(pipe, MODEL_PKL)\n",
    "print(f\"[SAVED] {MODEL_PKL}\")\n",
    "\n",
    "meta = {\n",
    "    \"embeddings_file\": str(emb_path),\n",
    "    \"topics_file\": str(topic_path),\n",
    "    \"n_samples\": int(X_all.shape[0]),\n",
    "    \"n_features\": int(X_all.shape[1]),\n",
    "    \"n_classes\": int(len(classes_all)),\n",
    "    \"test_size\": TEST_SIZE,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"topk_saved\": TOPK_SAVE,\n",
    "    \"have_predict_proba\": bool(have_proba),\n",
    "    \"metrics\": {\n",
    "        \"final_train_accuracy\": float(train_acc[-1]),\n",
    "        \"final_test_accuracy\": float(test_acc[-1]),\n",
    "        \"final_test_logloss\": float(test_logloss[-1]) if len(test_logloss) and not np.isnan(test_logloss[-1]) else None\n",
    "    }\n",
    "}\n",
    "with open(META_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "print(f\"[SAVED] {META_JSON}\")\n",
    "\n",
    "print(\"\\n[DONE] All artifacts saved in:\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b2d6d7-434b-480b-b4e9-a79c890ba0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
