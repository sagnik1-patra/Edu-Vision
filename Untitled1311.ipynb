{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ad945-894e-4c71-8264-b64b90301fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting text with PyPDF2…\n",
      "[SAVE] Extracted text -> C:\\Users\\sagni\\Downloads\\Edu Vision\\outputs\\R20CSE2202-OPERATING-SYSTEMS_text.txt (31347 words)\n",
      "[INFO] Loading summarizer: t5-small (safetensors)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aee173186a4bde906c05647016bf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sagni\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9b95f17f9a44059d9b1686b51911ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a04f8f8b7584fc9ae02beb0a2f6eea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934209a69a3740129f4b0c9fa7b77944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c1a05f60004a7ba6964971a8fea00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050394f9beae47d08709cbf8ac354aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Summarizing (short)…\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# EduVision — PDF Lecture Summarizer (URL or local .pdf)\n",
    "# Fixed to avoid torch>=2.6 requirement by preferring safetensors models\n",
    "# Saves transcript + short/medium/long summaries + bullet notes + key phrases\n",
    "# Output dir: C:\\Users\\sagni\\Downloads\\Edu Vision\\outputs\n",
    "# ================================================================\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import requests\n",
    "\n",
    "# ----------------- USER SETTINGS -----------------\n",
    "PDF_SOURCE = r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\R20CSE2202-OPERATING-SYSTEMS.pdf\"  # URL or local path\n",
    "OUT_DIR = Path(r\"C:\\Users\\sagni\\Downloads\\Edu Vision\\outputs\")\n",
    "\n",
    "# Model preference order (all have safetensors so we can avoid torch.load)\n",
    "# You can reorder if you want higher quality (bart-base > t5-small), at the cost of size.\n",
    "MODEL_CANDIDATES = [\n",
    "    # compact & reliable\n",
    "    (\"t5-small\", 1280),              # good speed; smaller context\n",
    "    (\"facebook/bart-base\", 1536),    # a bit larger; good quality\n",
    "    # add more if you want:\n",
    "    # (\"google/pegasus-xsum\", 1024),\n",
    "    # (\"google/pegasus-cnn_dailymail\", 1024),\n",
    "]\n",
    "\n",
    "DEVICE = \"cuda\" if False else \"cpu\"   # set True above if you have GPU configured\n",
    "SHORT_MAX_WORDS  = 120\n",
    "MEDIUM_MAX_WORDS = 250\n",
    "LONG_MAX_WORDS   = 500\n",
    "CHUNK_WORDS      = 1200\n",
    "CHUNK_OVERLAP    = 150\n",
    "ENABLE_OCR_FALLBACK = True\n",
    "OCR_DPI = 250\n",
    "\n",
    "# Silence Windows symlink warning from HF hub caches\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "# ----------------- Imports -----------------\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Optional OCR deps\n",
    "try:\n",
    "    from pdf2image import convert_from_path\n",
    "    have_pdf2image = True\n",
    "except Exception:\n",
    "    have_pdf2image = False\n",
    "\n",
    "# ----------------- Paths & helpers -----------------\n",
    "def ensure_outdir(p: Path): p.mkdir(parents=True, exist_ok=True)\n",
    "def is_url(s: str) -> bool: return s.lower().startswith((\"http://\",\"https://\"))\n",
    "\n",
    "def extract_text_pypdf2(pdf_path: Path) -> str:\n",
    "    try:\n",
    "        reader = PdfReader(str(pdf_path))\n",
    "        parts = []\n",
    "        for page in reader.pages:\n",
    "            parts.append(page.extract_text() or \"\")\n",
    "        return \"\\n\".join(parts).strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] PyPDF2 failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def ocr_pdf_to_text(pdf_path: Path, dpi: int = 250) -> str:\n",
    "    if not have_pdf2image:\n",
    "        print(\"[WARN] pdf2image not installed. OCR fallback not available.\")\n",
    "        return \"\"\n",
    "    try:\n",
    "        from PIL import Image\n",
    "        import pytesseract\n",
    "    except Exception:\n",
    "        print(\"[WARN] Pillow/pytesseract not available for OCR.\")\n",
    "        return \"\"\n",
    "    try:\n",
    "        images = convert_from_path(str(pdf_path), dpi=dpi)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] pdf2image convert failed: {e}\")\n",
    "        return \"\"\n",
    "    texts = []\n",
    "    for idx, img in enumerate(images, 1):\n",
    "        try:\n",
    "            texts.append(pytesseract.image_to_string(img))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] OCR page {idx} failed: {e}\")\n",
    "    return \"\\n\".join(texts).strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    print(\"[INFO] Extracting text with PyPDF2…\")\n",
    "    text = extract_text_pypdf2(pdf_path)\n",
    "    if text and len(text.split()) > 50:\n",
    "        return text\n",
    "    if ENABLE_OCR_FALLBACK:\n",
    "        print(\"[INFO] Vector text low/empty; trying OCR fallback…\")\n",
    "        ocr_text = ocr_pdf_to_text(pdf_path, dpi=OCR_DPI)\n",
    "        if ocr_text and len(ocr_text.split()) > 20:\n",
    "            return ocr_text\n",
    "    return text\n",
    "\n",
    "def chunk_text_words(text: str, chunk_words=CHUNK_WORDS, overlap=CHUNK_OVERLAP) -> List[str]:\n",
    "    words = re.findall(r\"\\S+\", text)\n",
    "    chunks, i = [], 0\n",
    "    while i < len(words):\n",
    "        j = min(i + chunk_words, len(words))\n",
    "        chunk = \" \".join(words[i:j]).strip()\n",
    "        if chunk: chunks.append(chunk)\n",
    "        i = j - overlap\n",
    "        if i <= 0: i = j\n",
    "        if i >= len(words): break\n",
    "    return chunks\n",
    "\n",
    "def words_count(s: str) -> int:\n",
    "    return len(re.findall(r\"\\S+\", s))\n",
    "\n",
    "# ----------------- Summarizer loader (safetensors-first) -----------------\n",
    "def load_summarizer_safetensors(candidates, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Try models in order; force `use_safetensors=True` so we don't hit torch.load.\n",
    "    Returns (tokenizer, model, max_input_tokens).\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for model_name, max_len in candidates:\n",
    "        try:\n",
    "            print(f\"[INFO] Loading summarizer: {model_name} (safetensors)\")\n",
    "            tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "            model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "                model_name,\n",
    "                use_safetensors=True,      # <— key to avoid torch.load on .bin\n",
    "                torch_dtype=torch.float32,\n",
    "                low_cpu_mem_usage=True,\n",
    "            )\n",
    "            if device == \"cuda\" and torch.cuda.is_available():\n",
    "                model = model.to(\"cuda\")\n",
    "            return tok, model, max_len\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Could not load {model_name} with safetensors: {e}\")\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Failed to load any summarizer. Last error: {last_err}\")\n",
    "\n",
    "def summarize_chunk(tok, model, text: str, target_words=150, max_input_tokens=1024):\n",
    "    # heuristic tokens target\n",
    "    max_new_tokens = max(64, int(target_words * 1.3))\n",
    "    inputs = tok(\n",
    "        [text],\n",
    "        truncation=True, padding=True, return_tensors=\"pt\",\n",
    "        max_length=max_input_tokens\n",
    "    )\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_beams=4, length_penalty=2.0, early_stopping=True\n",
    "        )\n",
    "    return tok.decode(out[0], skip_special_tokens=True).strip()\n",
    "\n",
    "def map_reduce_summarize(full_text: str, tok, model, target_words=200, max_input_tokens=1024):\n",
    "    chunks = chunk_text_words(full_text, CHUNK_WORDS, CHUNK_OVERLAP)\n",
    "    if not chunks:\n",
    "        return summarize_chunk(tok, model, full_text, target_words, max_input_tokens)\n",
    "    partials = [summarize_chunk(tok, model, ck, max(80, target_words//2), max_input_tokens) for ck in chunks]\n",
    "    joined = \" \".join(partials)\n",
    "    return summarize_chunk(tok, model, joined, target_words, max_input_tokens)\n",
    "\n",
    "def bulletize(text: str, max_bullets=14) -> List[str]:\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    KEYS = {\"key\",\"main\",\"important\",\"note\",\"definition\",\"example\",\"conclusion\",\"therefore\",\"because\",\"causes\",\"result\",\"summary\"}\n",
    "    scored = []\n",
    "    for s in sents:\n",
    "        t = s.strip()\n",
    "        if not t: continue\n",
    "        score = -abs(len(t.split()) - 18)\n",
    "        if any(k in t.lower() for k in KEYS): score += 3\n",
    "        scored.append((score, t))\n",
    "    scored.sort(reverse=True, key=lambda x: x[0])\n",
    "    return [t for _, t in scored[:max_bullets]]\n",
    "\n",
    "def top_key_phrases(text: str, top_k=25) -> List[str]:\n",
    "    stop = set(\"\"\"\n",
    "        a an the and or if in on with by for to of from that this these those as is are was were be been being have has had do does did not no yes it its it's\n",
    "        at into over under between within without through about across up down out off your you we they he she them his her our their than then there here\n",
    "    \"\"\".split())\n",
    "    tokens = [re.sub(r\"[^a-z0-9\\-]\", \"\", w.lower()) for w in re.findall(r\"\\b[\\w\\-']+\\b\", text)]\n",
    "    tokens = [t for t in tokens if t and t not in stop and not t.isdigit() and len(t) > 2]\n",
    "    from collections import Counter\n",
    "    unis = Counter(tokens)\n",
    "    bigs = Counter([\" \".join(tokens[i:i+2]) for i in range(len(tokens)-1)])\n",
    "    tris = Counter([\" \".join(tokens[i:i+3]) for i in range(len(tokens)-2)])\n",
    "    scores = {}\n",
    "    for k,v in unis.items(): scores[k] = scores.get(k,0) + v\n",
    "    for k,v in bigs.items(): scores[k] = scores.get(k,0) + v*2\n",
    "    for k,v in tris.items(): scores[k] = scores.get(k,0) + v*3\n",
    "    phrases = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    final, used = [], set()\n",
    "    for p,_ in phrases:\n",
    "        if any(p in u for u in used if p != u): continue\n",
    "        used.add(p); final.append(p)\n",
    "        if len(final) >= top_k: break\n",
    "    return final\n",
    "\n",
    "# ----------------- Main -----------------\n",
    "def main(pdf_source: str):\n",
    "    ensure_outdir(OUT_DIR)\n",
    "    src = pdf_source.strip().strip('\"')\n",
    "    if not src:\n",
    "        raise SystemExit(\"Set PDF_SOURCE to a PDF URL or local PDF path.\")\n",
    "\n",
    "    # 1) Resolve PDF path\n",
    "    if is_url(src):\n",
    "        print(\"[INFO] Downloading PDF…\")\n",
    "        r = requests.get(src, timeout=60); r.raise_for_status()\n",
    "        pdf_path = OUT_DIR / \"downloaded_lecture.pdf\"\n",
    "        pdf_path.write_bytes(r.content)\n",
    "        basename = \"online_lecture\"\n",
    "    else:\n",
    "        pdf_path = Path(src)\n",
    "        if not pdf_path.exists():\n",
    "            raise SystemExit(f\"PDF not found: {pdf_path}\")\n",
    "        basename = pdf_path.stem\n",
    "\n",
    "    # 2) Extract text\n",
    "    text = extract_text_from_pdf(pdf_path).strip()\n",
    "    if not text:\n",
    "        raise SystemExit(\"Could not extract text from PDF (even with OCR fallback).\")\n",
    "\n",
    "    # Light cleanup\n",
    "    text = re.sub(r\"[ \\t]+\\n\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "\n",
    "    transcript_path = OUT_DIR / f\"{basename}_text.txt\"\n",
    "    transcript_path.write_text(text, encoding=\"utf-8\")\n",
    "    print(f\"[SAVE] Extracted text -> {transcript_path} ({words_count(text)} words)\")\n",
    "\n",
    "    # 3) Load summarizer (safetensors-first)\n",
    "    tok, model, max_input_len = load_summarizer_safetensors(MODEL_CANDIDATES, DEVICE)\n",
    "\n",
    "    # 4) Summaries\n",
    "    print(\"[INFO] Summarizing (short)…\")\n",
    "    summary_short  = map_reduce_summarize(text, tok, model, target_words=SHORT_MAX_WORDS,  max_input_tokens=max_input_len)\n",
    "    print(\"[INFO] Summarizing (medium)…\")\n",
    "    summary_medium = map_reduce_summarize(text, tok, model, target_words=MEDIUM_MAX_WORDS, max_input_tokens=max_input_len)\n",
    "    print(\"[INFO] Summarizing (long)…\")\n",
    "    summary_long   = map_reduce_summarize(text, tok, model, target_words=LONG_MAX_WORDS,   max_input_tokens=max_input_len)\n",
    "\n",
    "    # 5) Notes & key phrases\n",
    "    bullets    = bulletize(summary_long, max_bullets=14)\n",
    "    keyphrases = top_key_phrases(text, top_k=25)\n",
    "\n",
    "    # 6) Save outputs\n",
    "    (OUT_DIR / f\"{basename}_summary_short.txt\").write_text(summary_short,  encoding=\"utf-8\")\n",
    "    (OUT_DIR / f\"{basename}_summary_medium.txt\").write_text(summary_medium, encoding=\"utf-8\")\n",
    "    (OUT_DIR / f\"{basename}_summary_long.txt\").write_text(summary_long,   encoding=\"utf-8\")\n",
    "    (OUT_DIR / f\"{basename}_notes.md\").write_text(\"# Bullet Notes\\n\\n\" + \"\\n\".join(f\"- {b}\" for b in bullets), encoding=\"utf-8\")\n",
    "\n",
    "    meta = {\n",
    "        \"input\": src,\n",
    "        \"device\": DEVICE,\n",
    "        \"model_loaded\": getattr(model.config, \"name_or_path\", str(MODEL_CANDIDATES[0][0])),\n",
    "        \"max_input_tokens\": max_input_len,\n",
    "        \"words_text\": words_count(text),\n",
    "        \"chunks_config\": {\"chunk_words\": CHUNK_WORDS, \"overlap\": CHUNK_OVERLAP},\n",
    "        \"lengths\": {\n",
    "            \"short_words\":  SHORT_MAX_WORDS,\n",
    "            \"medium_words\": MEDIUM_MAX_WORDS,\n",
    "            \"long_words\":   LONG_MAX_WORDS\n",
    "        },\n",
    "        \"key_phrases\": keyphrases[:25],\n",
    "    }\n",
    "    (OUT_DIR / f\"{basename}_meta.json\").write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\n[DONE] Saved:\")\n",
    "    print(\" -\", transcript_path)\n",
    "    print(\" -\", OUT_DIR / f\"{basename}_summary_short.txt\")\n",
    "    print(\" -\", OUT_DIR / f\"{basename}_summary_medium.txt\")\n",
    "    print(\" -\", OUT_DIR / f\"{basename}_summary_long.txt\")\n",
    "    print(\" -\", OUT_DIR / f\"{basename}_notes.md\")\n",
    "    print(\" -\", OUT_DIR / f\"{basename}_meta.json\")\n",
    "\n",
    "# ----------------- ENTRY -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    if PDF_SOURCE:\n",
    "        main(PDF_SOURCE)\n",
    "    else:\n",
    "        print(\"Please set PDF_SOURCE near the top of this script.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f638708-b46d-45ad-9483-7723b9403f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
